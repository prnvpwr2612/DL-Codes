{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743268d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, input_shape, filter_size, num_filters):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "        self.output_shape = (\n",
    "            num_filters,\n",
    "            input_shape[0] - filter_size + 1,\n",
    "            input_shape[1] - filter_size + 1\n",
    "        )\n",
    "        \n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size) * 0.01\n",
    "        self.biases = np.zeros(self.output_shape)\n",
    "        self.input_data = None\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        batch_size = input_data.shape[0]\n",
    "        output = np.zeros((batch_size, *self.output_shape))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for f in range(self.num_filters):\n",
    "                for h in range(self.output_shape[1]):\n",
    "                    for w in range(self.output_shape[2]):\n",
    "                        output[i, f, h, w] = np.sum(\n",
    "                            input_data[i, h:h+self.filter_size, w:w+self.filter_size] * self.filters[f]\n",
    "                        ) + self.biases[f, h, w]\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def backward(self, d_output, learning_rate):\n",
    "        batch_size = d_output.shape[0]\n",
    "        d_input = np.zeros_like(self.input_data)\n",
    "        d_filters = np.zeros_like(self.filters)\n",
    "        d_biases = np.zeros_like(self.biases)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for f in range(self.num_filters):\n",
    "                for h in range(self.output_shape[1]):\n",
    "                    for w in range(self.output_shape[2]):\n",
    "                        d_input[i, h:h+self.filter_size, w:w+self.filter_size] += d_output[i, f, h, w] * self.filters[f]\n",
    "                        d_filters[f] += d_output[i, f, h, w] * self.input_data[i, h:h+self.filter_size, w:w+self.filter_size]\n",
    "                        d_biases[f, h, w] += d_output[i, f, h, w]\n",
    "        \n",
    "        self.filters -= learning_rate * d_filters\n",
    "        self.biases -= learning_rate * d_biases\n",
    "        \n",
    "        return d_input\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        self.input_data = None\n",
    "        self.max_indices = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        batch_size, num_channels, input_height, input_width = input_data.shape\n",
    "        \n",
    "        output_height = input_height // self.pool_size\n",
    "        output_width = input_width // self.pool_size\n",
    "        \n",
    "        output = np.zeros((batch_size, num_channels, output_height, output_width))\n",
    "        self.max_indices = np.zeros_like(input_data, dtype=bool)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for c in range(num_channels):\n",
    "                for h in range(output_height):\n",
    "                    for w in range(output_width):\n",
    "                        h_start = h * self.pool_size\n",
    "                        w_start = w * self.pool_size\n",
    "                        h_end = h_start + self.pool_size\n",
    "                        w_end = w_start + self.pool_size\n",
    "                        \n",
    "                        pool_region = input_data[i, c, h_start:h_end, w_start:w_end]\n",
    "                        max_val = np.max(pool_region)\n",
    "                        max_idx = np.argmax(pool_region.flatten())\n",
    "                        max_idx_h, max_idx_w = np.unravel_index(max_idx, (self.pool_size, self.pool_size))\n",
    "                        \n",
    "                        output[i, c, h, w] = max_val\n",
    "                        self.max_indices[i, c, h_start + max_idx_h, w_start + max_idx_w] = True\n",
    "        \n",
    "        self.output = output\n",
    "        return output\n",
    "    \n",
    "    def backward(self, d_output):\n",
    "        batch_size, num_channels, output_height, output_width = d_output.shape\n",
    "        d_input = np.zeros_like(self.input_data)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for c in range(num_channels):\n",
    "                for h in range(output_height):\n",
    "                    for w in range(output_width):\n",
    "                        h_start = h * self.pool_size\n",
    "                        w_start = w * self.pool_size\n",
    "                        h_end = h_start + self.pool_size\n",
    "                        w_end = w_start + self.pool_size\n",
    "                        \n",
    "                        mask = self.max_indices[i, c, h_start:h_end, w_start:w_end]\n",
    "                        d_input[i, c, h_start:h_end, w_start:w_end][mask] = d_output[i, c, h, w]\n",
    "        \n",
    "        return d_input\n",
    "\n",
    "class GRU:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_z = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.U_z = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.b_z = np.zeros((1, hidden_size))\n",
    "        \n",
    "        self.W_r = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.U_r = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.b_r = np.zeros((1, hidden_size))\n",
    "        \n",
    "        self.W_h = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.U_h = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.b_h = np.zeros((1, hidden_size))\n",
    "        \n",
    "        self.x = None\n",
    "        self.z = None\n",
    "        self.r = None\n",
    "        self.h_candidate = None\n",
    "        self.h_prev = None\n",
    "        self.h = None\n",
    "    \n",
    "    def forward(self, x, h_prev=None):\n",
    "        if h_prev is None:\n",
    "            h_prev = np.zeros((x.shape[0], self.hidden_size))\n",
    "        \n",
    "        self.x = x\n",
    "        self.h_prev = h_prev\n",
    "        \n",
    "        self.z = sigmoid(np.dot(x, self.W_z) + np.dot(h_prev, self.U_z) + self.b_z)\n",
    "        self.r = sigmoid(np.dot(x, self.W_r) + np.dot(h_prev, self.U_r) + self.b_r)\n",
    "        self.h_candidate = tanh(np.dot(x, self.W_h) + np.dot(self.r * h_prev, self.U_h) + self.b_h)\n",
    "        self.h = (1 - self.z) * h_prev + self.z * self.h_candidate\n",
    "        \n",
    "        return self.h\n",
    "    \n",
    "    def backward(self, d_h, learning_rate, d_h_next=None):\n",
    "        if d_h_next is None:\n",
    "            d_h_next = np.zeros_like(d_h)\n",
    "        \n",
    "        d_h = d_h + d_h_next\n",
    "        \n",
    "        d_z = d_h * (self.h_candidate - self.h_prev)\n",
    "        d_h_candidate = d_h * self.z\n",
    "        d_h_prev = d_h * (1 - self.z)\n",
    "        \n",
    "        d_h_candidate_tanh = d_h_candidate * (1 - self.h_candidate**2)\n",
    "        d_r = np.dot(d_h_candidate_tanh, self.U_h.T) * self.h_prev\n",
    "        d_h_prev += np.dot(d_h_candidate_tanh, self.U_h.T) * self.r\n",
    "        d_x_h = np.dot(d_h_candidate_tanh, self.W_h.T)\n",
    "        \n",
    "        d_r_sigmoid = d_r * self.r * (1 - self.r)\n",
    "        d_x_r = np.dot(d_r_sigmoid, self.W_r.T)\n",
    "        d_h_prev += np.dot(d_r_sigmoid, self.U_r.T)\n",
    "        \n",
    "        d_z_sigmoid = d_z * self.z * (1 - self.z)\n",
    "        d_x_z = np.dot(d_z_sigmoid, self.W_z.T)\n",
    "        d_h_prev += np.dot(d_z_sigmoid, self.U_z.T)\n",
    "        \n",
    "        d_x = d_x_h + d_x_r + d_x_z\n",
    "        \n",
    "        self.W_z -= learning_rate * np.dot(self.x.T, d_z_sigmoid)\n",
    "        self.U_z -= learning_rate * np.dot(self.h_prev.T, d_z_sigmoid)\n",
    "        self.b_z -= learning_rate * np.sum(d_z_sigmoid, axis=0, keepdims=True)\n",
    "        \n",
    "        self.W_r -= learning_rate * np.dot(self.x.T, d_r_sigmoid)\n",
    "        self.U_r -= learning_rate * np.dot(self.h_prev.T, d_r_sigmoid)\n",
    "        self.b_r -= learning_rate * np.sum(d_r_sigmoid, axis=0, keepdims=True)\n",
    "        \n",
    "        self.W_h -= learning_rate * np.dot(self.x.T, d_h_candidate_tanh)\n",
    "        self.U_h -= learning_rate * np.dot((self.r * self.h_prev).T, d_h_candidate_tanh)\n",
    "        self.b_h -= learning_rate * np.sum(d_h_candidate_tanh, axis=0, keepdims=True)\n",
    "        \n",
    "        return d_x, d_h_prev\n",
    "\n",
    "class FullyConnected:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.01\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "        self.input_data = None\n",
    "        self.output = None\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        self.output = np.dot(input_data, self.weights) + self.biases\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, d_output, learning_rate):\n",
    "        d_input = np.dot(d_output, self.weights.T)\n",
    "        d_weights = np.dot(self.input_data.T, d_output)\n",
    "        d_biases = np.sum(d_output, axis=0, keepdims=True)\n",
    "        \n",
    "        self.weights -= learning_rate * d_weights\n",
    "        self.biases -= learning_rate * d_biases\n",
    "        \n",
    "        return d_input\n",
    "\n",
    "class HybridCNNRNN:\n",
    "    def __init__(self, input_shape, filter_size, num_filters, pool_size, hidden_size, output_size):\n",
    "        self.conv = Convolution(input_shape, filter_size, num_filters)\n",
    "        \n",
    "        conv_output_shape = (\n",
    "            num_filters,\n",
    "            input_shape[0] - filter_size + 1,\n",
    "            input_shape[1] - filter_size + 1\n",
    "        )\n",
    "        \n",
    "        self.pool = Pooling(pool_size)\n",
    "        pool_output_shape = (\n",
    "            num_filters,\n",
    "            conv_output_shape[1] // pool_size,\n",
    "            conv_output_shape[2] // pool_size\n",
    "        )\n",
    "        \n",
    "        self.flatten_size = pool_output_shape[0] * pool_output_shape[1] * pool_output_shape[2]\n",
    "        self.gru = GRU(self.flatten_size, hidden_size)\n",
    "        self.fc = FullyConnected(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        if input_data.ndim == 2:\n",
    "            input_data = np.expand_dims(input_data, axis=0)\n",
    "        \n",
    "        conv_output = self.conv.forward(input_data)\n",
    "        pool_output = self.pool.forward(conv_output)\n",
    "        \n",
    "        batch_size = pool_output.shape[0]\n",
    "        flattened = pool_output.reshape(batch_size, -1)\n",
    "        \n",
    "        gru_output = self.gru.forward(flattened)\n",
    "        fc_output = self.fc.forward(gru_output)\n",
    "        \n",
    "        return softmax(fc_output)\n",
    "    \n",
    "    def backward(self, y_true, learning_rate):\n",
    "        d_output = softmax(self.fc.output) - y_true\n",
    "        d_fc = self.fc.backward(d_output, learning_rate)\n",
    "        d_gru, _ = self.gru.backward(d_fc, learning_rate)\n",
    "        \n",
    "        batch_size = d_gru.shape[0]\n",
    "        d_pool = d_gru.reshape(self.pool.output.shape)\n",
    "        \n",
    "        d_conv = self.pool.backward(d_pool)\n",
    "        _ = self.conv.backward(d_conv, learning_rate)\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate, batch_size=32):\n",
    "        num_samples = X.shape[0]\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            indices = np.random.permutation(num_samples)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "            \n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                X_batch = X_shuffled[i:i+batch_size]\n",
    "                y_batch = y_shuffled[i:i+batch_size]\n",
    "                \n",
    "                _ = self.forward(X_batch)\n",
    "                self.backward(y_batch, learning_rate)\n",
    "            \n",
    "            predictions = self.predict(X)\n",
    "            accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y, axis=1))\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "def preprocess_iris_data(data, target_shape=(8, 8)):\n",
    "    if data.ndim > 1 and data.shape[0] > 1:\n",
    "        normalized_data = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "    else:\n",
    "        means = np.array([5.84, 3.05, 3.76, 1.20])\n",
    "        stds = np.array([0.83, 0.43, 1.76, 0.76])\n",
    "        normalized_data = (data - means) / stds\n",
    "    \n",
    "    matrix_data = normalized_data.reshape(-1, 2, 2)\n",
    "    \n",
    "    upsampled_data = np.zeros((normalized_data.shape[0], target_shape[0], target_shape[1]))\n",
    "    \n",
    "    for i in range(normalized_data.shape[0]):\n",
    "        for h in range(target_shape[0]):\n",
    "            for w in range(target_shape[1]):\n",
    "                h_orig = min(int(h * 2 / target_shape[0]), 1)\n",
    "                w_orig = min(int(w * 2 / target_shape[1]), 1)\n",
    "                upsampled_data[i, h, w] = matrix_data[i, h_orig, w_orig]\n",
    "    \n",
    "    return upsampled_data\n",
    "\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    encoded = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        encoded[i, label] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a14aa177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Accuracy: 0.3417\n",
      "Epoch 2/20, Accuracy: 0.3417\n",
      "Epoch 3/20, Accuracy: 0.3417\n",
      "Epoch 4/20, Accuracy: 0.3417\n",
      "Epoch 5/20, Accuracy: 0.3417\n",
      "Epoch 6/20, Accuracy: 0.3417\n",
      "Epoch 7/20, Accuracy: 0.3417\n",
      "Epoch 8/20, Accuracy: 0.3417\n",
      "Epoch 9/20, Accuracy: 0.6750\n",
      "Epoch 10/20, Accuracy: 0.6667\n",
      "Epoch 11/20, Accuracy: 0.6750\n",
      "Epoch 12/20, Accuracy: 0.8000\n",
      "Epoch 13/20, Accuracy: 0.7667\n",
      "Epoch 14/20, Accuracy: 0.7000\n",
      "Epoch 15/20, Accuracy: 0.7333\n",
      "Epoch 16/20, Accuracy: 0.7750\n",
      "Epoch 17/20, Accuracy: 0.8250\n",
      "Epoch 18/20, Accuracy: 0.8667\n",
      "Epoch 19/20, Accuracy: 0.8667\n",
      "Epoch 20/20, Accuracy: 0.8750\n",
      "Test Accuracy: 0.9667\n",
      "Epoch 1/20, Accuracy: 0.3333\n",
      "Epoch 2/20, Accuracy: 0.3333\n",
      "Epoch 3/20, Accuracy: 0.3417\n",
      "Epoch 4/20, Accuracy: 0.3417\n",
      "Epoch 5/20, Accuracy: 0.3417\n",
      "Epoch 6/20, Accuracy: 0.3417\n",
      "Epoch 7/20, Accuracy: 0.3417\n",
      "Epoch 8/20, Accuracy: 0.3417\n",
      "Epoch 9/20, Accuracy: 0.3750\n",
      "Epoch 10/20, Accuracy: 0.6750\n",
      "Epoch 11/20, Accuracy: 0.6833\n",
      "Epoch 12/20, Accuracy: 0.8417\n",
      "Epoch 13/20, Accuracy: 0.7000\n",
      "Epoch 14/20, Accuracy: 0.7333\n",
      "Epoch 15/20, Accuracy: 0.8000\n",
      "Epoch 16/20, Accuracy: 0.8333\n",
      "Epoch 17/20, Accuracy: 0.8417\n",
      "Epoch 18/20, Accuracy: 0.8750\n",
      "Epoch 19/20, Accuracy: 0.8667\n",
      "Epoch 20/20, Accuracy: 0.8917\n",
      "Test Accuracy: 0.9667\n",
      "Predicted class: setosa\n",
      "Probability: 0.9797\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    X_train_processed = preprocess_iris_data(X_train)\n",
    "    X_test_processed = preprocess_iris_data(X_test)\n",
    "    \n",
    "    num_classes = len(np.unique(y))\n",
    "    y_train_encoded = one_hot_encode(y_train, num_classes)\n",
    "    y_test_encoded = one_hot_encode(y_test, num_classes)\n",
    "    \n",
    "    input_shape = (8, 8)\n",
    "    filter_size = 3\n",
    "    num_filters = 8\n",
    "    pool_size = 2\n",
    "    hidden_size = 32\n",
    "    output_size = num_classes\n",
    "    \n",
    "    model = HybridCNNRNN(input_shape, filter_size, num_filters, pool_size, hidden_size, output_size)\n",
    "    model.train(X_train_processed, y_train_encoded, epochs=20, learning_rate=0.01, batch_size=16)\n",
    "    \n",
    "    test_predictions = model.predict(X_test_processed)\n",
    "    test_accuracy = np.mean(np.argmax(test_predictions, axis=1) == np.argmax(y_test_encoded, axis=1))\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return model, iris.target_names\n",
    "\n",
    "def predict_with_user_input(model, iris_classes):\n",
    "    def predict_iris(sepal_length, sepal_width, petal_length, petal_width):\n",
    "        input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
    "        processed_data = preprocess_iris_data(input_data)\n",
    "        prediction = model.predict(processed_data)\n",
    "        class_idx = np.argmax(prediction[0])\n",
    "        probability = prediction[0, class_idx]\n",
    "        \n",
    "        return {\n",
    "            \"class\": iris_classes[class_idx],\n",
    "            \"probability\": float(probability),\n",
    "            \"raw_probabilities\": prediction[0].tolist()\n",
    "        }\n",
    "    \n",
    "    # Example usage:\n",
    "    model, iris_classes = train_model()\n",
    "    result = predict_iris(5.1, 3.5, 1.4, 0.2)\n",
    "    print(f\"Predicted class: {result['class']}\")\n",
    "    print(f\"Probability: {result['probability']:.4f}\")\n",
    "    \n",
    "    return predict_iris\n",
    "\n",
    "model, iris_classes = train_model()\n",
    "predictor = predict_with_user_input(model, iris_classes)\n",
    "result = predictor(5.1, 3.5, 1.4, 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
